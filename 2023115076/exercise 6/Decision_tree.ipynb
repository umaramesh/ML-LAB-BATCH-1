{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DECISION TREE**"
      ],
      "metadata": {
        "id": "5dniQCmBP4Xt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ID3 ALGORITHM**"
      ],
      "metadata": {
        "id": "g4M_G7eSP-K9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_P84NNDPRrt",
        "outputId": "9f30a89f-ffc5-4751-c340-7699ab0130cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "petal length (cm) <= 1.90?\n",
            "→ yes:\n",
            "    Predict → 0\n",
            "→ no:\n",
            "    petal width (cm) <= 1.70?\n",
            "    → yes:\n",
            "        petal length (cm) <= 4.90?\n",
            "        → yes:\n",
            "            Predict → 1\n",
            "        → no:\n",
            "            Predict → 2\n",
            "    → no:\n",
            "        petal length (cm) <= 4.80?\n",
            "        → yes:\n",
            "            Predict → 2\n",
            "        → no:\n",
            "            Predict → 2\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import log2\n",
        "\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target, name=\"target\")\n",
        "data = X.copy()\n",
        "data[\"target\"] = y\n",
        "\n",
        "def entropy(column):\n",
        "    values, counts = np.unique(column, return_counts=True)\n",
        "    return -np.sum((counts / np.sum(counts)) * np.log2(counts / np.sum(counts)))\n",
        "\n",
        "def info_gain(data, feature, target):\n",
        "    total_entropy = entropy(data[target])\n",
        "    thresholds = np.unique(data[feature])\n",
        "    best_gain = 0\n",
        "    best_thresh = None\n",
        "    for t in thresholds:\n",
        "        left = data[data[feature] <= t]\n",
        "        right = data[data[feature] > t]\n",
        "        if len(left) == 0 or len(right) == 0:\n",
        "            continue\n",
        "        p = len(left) / len(data)\n",
        "        gain = total_entropy - (p * entropy(left[target]) + (1 - p) * entropy(right[target]))\n",
        "        if gain > best_gain:\n",
        "            best_gain = gain\n",
        "            best_thresh = t\n",
        "    return best_gain, best_thresh\n",
        "\n",
        "def ID3(data, features, target, depth=0, max_depth=3):\n",
        "    labels = data[target]\n",
        "    if len(np.unique(labels)) == 1 or len(features) == 0 or depth == max_depth:\n",
        "        return np.bincount(labels).argmax()\n",
        "    gains = {}\n",
        "    thresholds = {}\n",
        "    for feature in features:\n",
        "        gain, thresh = info_gain(data, feature, target)\n",
        "        gains[feature] = gain\n",
        "        thresholds[feature] = thresh\n",
        "    best_feature = max(gains, key=gains.get)\n",
        "    best_threshold = thresholds[best_feature]\n",
        "    if best_threshold is None:\n",
        "        return np.bincount(labels).argmax()\n",
        "    tree = {f\"{best_feature} <= {best_threshold:.2f}\": {}}\n",
        "    left = data[data[best_feature] <= best_threshold]\n",
        "    right = data[data[best_feature] > best_threshold]\n",
        "    tree[f\"{best_feature} <= {best_threshold:.2f}\"][\"yes\"] = ID3(left, features, target, depth+1, max_depth)\n",
        "    tree[f\"{best_feature} <= {best_threshold:.2f}\"][\"no\"] = ID3(right, features, target, depth+1, max_depth)\n",
        "    return tree\n",
        "\n",
        "def print_tree(tree, indent=\"\"):\n",
        "    if isinstance(tree, dict):\n",
        "        for key, value in tree.items():\n",
        "            print(f\"{indent}{key}?\")\n",
        "            for branch in value:\n",
        "                print(f\"{indent}→ {branch}:\")\n",
        "                print_tree(value[branch], indent + \"    \")\n",
        "    else:\n",
        "        print(f\"{indent}Predict → {tree}\")\n",
        "features = X.columns.tolist()\n",
        "tree = ID3(data, features, \"target\", max_depth=3)\n",
        "print_tree(tree)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C4.5 ALGORITHM**"
      ],
      "metadata": {
        "id": "1ZH_yrPFQDJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import log2\n",
        "\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target, name=\"target\")\n",
        "data = X.copy()\n",
        "data[\"target\"] = y\n",
        "\n",
        "def entropy(column):\n",
        "    values, counts = np.unique(column, return_counts=True)\n",
        "    return -np.sum((counts / np.sum(counts)) * np.log2(counts / np.sum(counts)))\n",
        "\n",
        "def split_info(subsets, total_size):\n",
        "    return -np.sum([(len(subset)/total_size) * log2(len(subset)/total_size) for subset in subsets if len(subset) > 0])\n",
        "\n",
        "def gain_ratio(data, feature, target):\n",
        "    total_entropy = entropy(data[target])\n",
        "    thresholds = np.unique(data[feature])\n",
        "    best_gain_ratio = 0\n",
        "    best_thresh = None\n",
        "    for t in thresholds:\n",
        "        left = data[data[feature] <= t]\n",
        "        right = data[data[feature] > t]\n",
        "        if len(left) == 0 or len(right) == 0:\n",
        "            continue\n",
        "        p = len(left) / len(data)\n",
        "        gain = total_entropy - (p * entropy(left[target]) + (1 - p) * entropy(right[target]))\n",
        "        si = split_info([left, right], len(data))\n",
        "        if si == 0:\n",
        "            continue\n",
        "        ratio = gain / si\n",
        "        if ratio > best_gain_ratio:\n",
        "            best_gain_ratio = ratio\n",
        "            best_thresh = t\n",
        "    return best_gain_ratio, best_thresh\n",
        "\n",
        "def C45(data, features, target, depth=0, max_depth=3):\n",
        "    labels = data[target]\n",
        "    if len(np.unique(labels)) == 1 or len(features) == 0 or depth == max_depth:\n",
        "        return np.bincount(labels).argmax()\n",
        "    best_feature = None\n",
        "    best_threshold = None\n",
        "    best_ratio = -1\n",
        "    for feature in features:\n",
        "        ratio, thresh = gain_ratio(data, feature, target)\n",
        "        if ratio > best_ratio:\n",
        "            best_ratio = ratio\n",
        "            best_feature = feature\n",
        "            best_threshold = thresh\n",
        "    if best_feature is None or best_threshold is None:\n",
        "        return np.bincount(labels).argmax()\n",
        "    tree = {f\"{best_feature} <= {best_threshold:.2f}\": {}}\n",
        "    left = data[data[best_feature] <= best_threshold]\n",
        "    right = data[data[best_feature] > best_threshold]\n",
        "    tree[f\"{best_feature} <= {best_threshold:.2f}\"][\"yes\"] = C45(left, features, target, depth+1, max_depth)\n",
        "    tree[f\"{best_feature} <= {best_threshold:.2f}\"][\"no\"] = C45(right, features, target, depth+1, max_depth)\n",
        "    return tree\n",
        "\n",
        "def print_tree(tree, indent=\"\"):\n",
        "    if isinstance(tree, dict):\n",
        "        for key, value in tree.items():\n",
        "            print(f\"{indent}{key}?\")\n",
        "            for branch in value:\n",
        "                print(f\"{indent}→ {branch}:\")\n",
        "                print_tree(value[branch], indent + \"    \")\n",
        "    else:\n",
        "        print(f\"{indent}Predict → {tree}\")\n",
        "\n",
        "features = X.columns.tolist()\n",
        "tree = C45(data, features, \"target\", max_depth=3)\n",
        "print_tree(tree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wolrY6J2Pd0U",
        "outputId": "2ee306ac-f022-4345-9705-afefdc66e759"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "petal length (cm) <= 1.90?\n",
            "→ yes:\n",
            "    Predict → 0\n",
            "→ no:\n",
            "    petal width (cm) <= 1.70?\n",
            "    → yes:\n",
            "        petal length (cm) <= 5.10?\n",
            "        → yes:\n",
            "            Predict → 1\n",
            "        → no:\n",
            "            Predict → 2\n",
            "    → no:\n",
            "        petal length (cm) <= 4.80?\n",
            "        → yes:\n",
            "            Predict → 2\n",
            "        → no:\n",
            "            Predict → 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CART ALGORITHM**"
      ],
      "metadata": {
        "id": "xeqdJJ_GQHsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target, name=\"target\")\n",
        "data = X.copy()\n",
        "data[\"target\"] = y\n",
        "\n",
        "def gini(column):\n",
        "    values, counts = np.unique(column, return_counts=True)\n",
        "    prob_sq = (counts / np.sum(counts)) ** 2\n",
        "    return 1 - np.sum(prob_sq)\n",
        "\n",
        "def gini_index(data, feature, target):\n",
        "    thresholds = np.unique(data[feature])\n",
        "    best_gini = float('inf')\n",
        "    best_thresh = None\n",
        "    for t in thresholds:\n",
        "        left = data[data[feature] <= t]\n",
        "        right = data[data[feature] > t]\n",
        "        if len(left) == 0 or len(right) == 0:\n",
        "            continue\n",
        "        p_left = len(left) / len(data)\n",
        "        p_right = len(right) / len(data)\n",
        "        g = p_left * gini(left[target]) + p_right * gini(right[target])\n",
        "        if g < best_gini:\n",
        "            best_gini = g\n",
        "            best_thresh = t\n",
        "    return best_gini, best_thresh\n",
        "\n",
        "def CART(data, features, target, depth=0, max_depth=3):\n",
        "    labels = data[target]\n",
        "    if len(np.unique(labels)) == 1 or len(features) == 0 or depth == max_depth:\n",
        "        return np.bincount(labels).argmax()\n",
        "    best_feature = None\n",
        "    best_threshold = None\n",
        "    best_gini = float('inf')\n",
        "    for feature in features:\n",
        "        gini_val, thresh = gini_index(data, feature, target)\n",
        "        if gini_val < best_gini:\n",
        "            best_gini = gini_val\n",
        "            best_feature = feature\n",
        "            best_threshold = thresh\n",
        "    if best_feature is None or best_threshold is None:\n",
        "        return np.bincount(labels).argmax()\n",
        "    tree = {f\"{best_feature} <= {best_threshold:.2f}\": {}}\n",
        "    left = data[data[best_feature] <= best_threshold]\n",
        "    right = data[data[best_feature] > best_threshold]\n",
        "    tree[f\"{best_feature} <= {best_threshold:.2f}\"][\"yes\"] = CART(left, features, target, depth+1, max_depth)\n",
        "    tree[f\"{best_feature} <= {best_threshold:.2f}\"][\"no\"] = CART(right, features, target, depth+1, max_depth)\n",
        "    return tree\n",
        "\n",
        "def print_tree(tree, indent=\"\"):\n",
        "    if isinstance(tree, dict):\n",
        "        for key, value in tree.items():\n",
        "            print(f\"{indent}{key}?\")\n",
        "            for branch in value:\n",
        "                print(f\"{indent}→ {branch}:\")\n",
        "                print_tree(value[branch], indent + \"    \")\n",
        "    else:\n",
        "        print(f\"{indent}Predict → {tree}\")\n",
        "\n",
        "features = X.columns.tolist()\n",
        "tree = CART(data, features, \"target\", max_depth=3)\n",
        "print_tree(tree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7w1cK0MPiIo",
        "outputId": "69122206-88e0-4cc2-90de-80534f21f5e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "petal length (cm) <= 1.90?\n",
            "→ yes:\n",
            "    Predict → 0\n",
            "→ no:\n",
            "    petal width (cm) <= 1.70?\n",
            "    → yes:\n",
            "        petal length (cm) <= 4.90?\n",
            "        → yes:\n",
            "            Predict → 1\n",
            "        → no:\n",
            "            Predict → 2\n",
            "    → no:\n",
            "        petal length (cm) <= 4.80?\n",
            "        → yes:\n",
            "            Predict → 2\n",
            "        → no:\n",
            "            Predict → 2\n"
          ]
        }
      ]
    }
  ]
}